{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7faecf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import argparse\n",
    "\n",
    "import multiqa_utils.general_utils as gu\n",
    "import multiqa_utils.qampari_utils as qu\n",
    "import multiqa_utils.retrieval_utils as ru\n",
    "import multiqa_utils.wikipedia_utils as wu\n",
    "import multiqa_utils.distributed_utils as du\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc63a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d918dea8",
   "metadata": {},
   "source": [
    "## First, build the ent_string to wikipage_title cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286fb18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_args = gu.current_default_path_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc7e4258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Index already exists: /scratch/ddr8143/wikipedia/tagme_dumps_qampari_wikipedia/postprocessed/gt_title_set.json\n"
     ]
    }
   ],
   "source": [
    "all_titles = wu.build_gt_wikititle_set(path_args, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1365d0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading the cache\n",
      ">> Initial cache size: 7198496\n"
     ]
    }
   ],
   "source": [
    "curr_cache = wu.get_initial_str2wikipage_cache(all_titles, path_args, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without any flags set true (add_elq, add_gpt, add_wikitags) this just\n",
    "#   goes through the current list and removes strings already in cache.\n",
    "ru.aggregate_strs_to_add_to_cache(\n",
    "    path_args,\n",
    "    use_tqdm=True,\n",
    "    curr_cache=curr_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strs_to_add = json.load(open(path_args.strs_for_cache_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cdd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "du.distributed_build_str2wikipage_cache(\n",
    "    path_args,\n",
    "    job_id=0,\n",
    "    total_num_jobs=40000,\n",
    "    all_strs_to_add=strs_to_add,\n",
    "    use_tqdm=True,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0da01",
   "metadata": {},
   "source": [
    "**After a Distributed Run, aggregate the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3701553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Aggregating all 11 versions of: /scratch/ddr8143/wikipedia/tagme_dumps_qampari_wikipedia/postprocessed/str2wikipage_cache.json\n",
      ">> Length of final dict: 7814969\n",
      ">> Dumped: /scratch/ddr8143/wikipedia/tagme_dumps_qampari_wikipedia/postprocessed/str2wikipage_cache.json\n",
      ">> Intermediate files have been removed\n"
     ]
    }
   ],
   "source": [
    "du.aggregate_checkpoint_dicts(path_args.cache_path, remove_processed=True, dry_run_remove=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732fc3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Aggregating all 11 versions of: /scratch/ddr8143/wikipedia/tagme_dumps_qampari_wikipedia/postprocessed/str2wikipage_disambig_cache.json\n",
      ">> Length of final dict: 8606\n",
      ">> Dumped: /scratch/ddr8143/wikipedia/tagme_dumps_qampari_wikipedia/postprocessed/str2wikipage_disambig_cache.json\n",
      ">> Intermediate files have been removed\n"
     ]
    }
   ],
   "source": [
    "du.aggregate_checkpoint_dicts(path_args.disambig_cache_path, remove_processed=True, dry_run_remove=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f53f631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading the cache\n",
      ">> Initial cache size: 7814969\n"
     ]
    }
   ],
   "source": [
    "curr_cache = wu.get_initial_str2wikipage_cache(all_titles, path_args, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60489a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Load existing string list: /scratch/ddr8143/wikipedia/tagme_dumps_qampari_wikipedia/postprocessed/strs_to_add_to_cache_v1.json\n",
      ">> Initial string list length: 889318\n",
      ">> Removing strings already in cache\n",
      ">> New string list length: 272845\n",
      ">> Writing file\n",
      ">> Dumped to: /scratch/ddr8143/wikipedia/tagme_dumps_qampari_wikipedia/postprocessed/strs_to_add_to_cache_v1.json\n"
     ]
    }
   ],
   "source": [
    "# Without any flags set true (add_elq, add_gpt, add_wikitags) this just\n",
    "#   goes through the current list and removes strings already in cache.\n",
    "ru.aggregate_strs_to_add_to_cache(\n",
    "    path_args,\n",
    "    use_tqdm=True,\n",
    "    curr_cache=curr_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1c62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strs_to_add = json.load(open(path_args.strs_for_cache_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb61f690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Cache size: 7,814,969 Unmatched strings: 272,845\n"
     ]
    }
   ],
   "source": [
    "print(f\">> Cache size: {len(curr_cache):,} Unmatched strings: {len(strs_to_add):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163d6a7",
   "metadata": {},
   "source": [
    "**AND WERE DONE!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebc71711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unneeded_lookup_strings(init_list, text_cache_set, notext_cache_set):\n",
    "    init_len = len(init_list)\n",
    "    print(\">> Initial list length:\", init_len)\n",
    "    \n",
    "    # Remove all cases that start with hashes\n",
    "    new_list = [s for s in init_list if s[0] != '#']\n",
    "    print(\">> After removing start with hashes:\", len(new_list))\n",
    "    \n",
    "    # Replace cases with hashes with just the part before the anchor\n",
    "    new_list = [s if '#' not in s else s.split('#')[0] for s in new_list]\n",
    "    new_list = [s for s in new_list if s not in text_cache_set]\n",
    "    print(\">> After removing anchors:\", len(new_list))\n",
    "    \n",
    "    # Remove all that are in notext cache set (fixed by redirects)\n",
    "    new_list = [s for s in new_list if s not in notext_cache_set]\n",
    "    print(\">> After removing redirects:\", len(new_list))\n",
    "    \n",
    "    # Fix amps in both directions\n",
    "    new_list = [s.replace('&amp;', '&') for s in new_list]\n",
    "    new_list = [s for s in new_list if s not in notext_cache_set and s not in text_cache_set]\n",
    "    new_list = [s.replace('&', '&amp;') for s in new_list]\n",
    "    new_list = [s for s in new_list if s not in notext_cache_set and s not in text_cache_set]\n",
    "    print(\">> After fixing amps:\", len(new_list))\n",
    "    \n",
    "    final_len = len(new_list)\n",
    "    removed = init_len - final_len\n",
    "    print(f\"Removed {removed} strings: {removed * 100.0 / init_len:0.2f}% of the list\")\n",
    "    print(\"Final Length:\", len(new_list))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "252071e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "strs_to_add = json.load(open(path_args.strs_for_cache_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea13145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "033b6e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpkl(filename):\n",
    "    return pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d8045d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_set = set(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb307010",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirects = loadpkl('/scratch/ddr8143/wikipedia/old_redirects.pkl')\n",
    "redirects_set = set(redirects.keys())\n",
    "redirects_onesteptotext = {k: v for k, v in redirects.items() if v in all_titles_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24bdd1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Initial list length: 272845\n",
      ">> After removing start with hashes: 272845\n",
      ">> After removing anchors: 272845\n",
      ">> After removing redirects: 272604\n",
      ">> After fixing amps: 272604\n",
      "Removed 241 strings: 0.09% of the list\n",
      "Final Length: 272604\n"
     ]
    }
   ],
   "source": [
    "new_strs_to_add = remove_unneeded_lookup_strings(strs_to_add, all_titles_set, set(redirects_onesteptotext.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c37ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Init strings to add: 272,845 final: 272,604\n"
     ]
    }
   ],
   "source": [
    "print(f\">> Init strings to add: {len(strs_to_add):,} final: {len(new_strs_to_add):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742deb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b016540c",
   "metadata": {},
   "source": [
    "## Try to see if we can identify redirects ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f3dacefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion, the way we could do it is to call the online API\n",
    "#import requests\n",
    "def call_online_redirect_api(existing_page_name):\n",
    "    S = requests.Session()\n",
    "\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": existing_page_name,\n",
    "        \"prop\": \"redirects\"\n",
    "    }\n",
    "\n",
    "    R = S.get(url=URL, params=PARAMS)\n",
    "    DATA = R.json()\n",
    "\n",
    "    PAGES = DATA[\"query\"][\"pages\"]\n",
    "\n",
    "\n",
    "    redirects = []\n",
    "    for k, v in PAGES.items():\n",
    "        if 'redirects' in v:\n",
    "            for re in v[\"redirects\"]:\n",
    "                redirects.append(re['title'])\n",
    "                print(re[\"title\"] + \" redirect to \" + v[\"title\"])\n",
    "    return redirects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cb179101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_redirect_title(url_str, session=None):\n",
    "    if session is None:\n",
    "        session = requests.Session()\n",
    "    response = session.get(url=url_str)\n",
    "    title = [l for l in response.text.split('\\n') if '<title>' in l]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f0371afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ED_wiki_35 = gu.loadjsonl(\"/scratch/ddr8143/wikipedia/qampari_wikipedia/parsed_dumps/AA/wiki_35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "684cdb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '3619', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3619', 'title': 'Military of Botswana', 'text': ''}\n",
      "{'id': '3622', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3622', 'title': 'Geography of Bouvet Island', 'text': ''}\n",
      "{'id': '3623', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3623', 'title': 'Bouvet Island/People', 'text': ''}\n",
      "{'id': '3624', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3624', 'title': 'Government of Bouvet Island', 'text': ''}\n",
      "{'id': '3625', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3625', 'title': 'Economy of Bouvet Island', 'text': ''}\n",
      "{'id': '3626', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3626', 'title': 'Communications in Bouvet Island', 'text': ''}\n",
      "{'id': '3627', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3627', 'title': 'Bouvet Island/Transportation', 'text': ''}\n",
      "{'id': '3628', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3628', 'title': 'Military of Bouvet Island', 'text': ''}\n",
      "{'id': '3640', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3640', 'title': 'British Indian Ocean Territory/Geography', 'text': ''}\n",
      "{'id': '3641', 'revid': '5286041', 'url': 'https://en.wikipedia.org/wiki?curid=3641', 'title': 'Demographics of the British Indian Ocean Territory', 'text': ''}\n",
      "{'id': '3642', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3642', 'title': 'British Indian Ocean Territory/Government', 'text': ''}\n",
      "{'id': '3643', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3643', 'title': 'British Indian Ocean Territory/Economy', 'text': ''}\n",
      "{'id': '3644', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3644', 'title': 'British Indian Ocean Territory/Communications', 'text': ''}\n",
      "{'id': '3645', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3645', 'title': 'British Indian Ocean Territory/Transportation', 'text': ''}\n",
      "{'id': '3646', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3646', 'title': 'British Indian Ocean Territory/Military', 'text': ''}\n",
      "{'id': '3647', 'revid': '20836525', 'url': 'https://en.wikipedia.org/wiki?curid=3647', 'title': 'British Indian Ocean Territory/Transnational issues', 'text': ''}\n",
      "{'id': '3656', 'revid': '30', 'url': 'https://en.wikipedia.org/wiki?curid=3656', 'title': 'Transnational issues of the British Virgin Islands', 'text': ''}\n",
      "{'id': '3686', 'revid': '20836525', 'url': 'https://en.wikipedia.org/wiki?curid=3686', 'title': 'Burma/Geography', 'text': ''}\n",
      "{'id': '3689', 'revid': '20836525', 'url': 'https://en.wikipedia.org/wiki?curid=3689', 'title': 'Burma/Economy', 'text': ''}\n",
      "{'id': '3690', 'revid': '20836525', 'url': 'https://en.wikipedia.org/wiki?curid=3690', 'title': 'Burma/Communications', 'text': ''}\n",
      "{'id': '3723', 'revid': '9784415', 'url': 'https://en.wikipedia.org/wiki?curid=3723', 'title': 'Bse', 'text': ''}\n",
      "{'id': '3726', 'revid': '19818307', 'url': 'https://en.wikipedia.org/wiki?curid=3726', 'title': 'Breakdance', 'text': ''}\n",
      "{'id': '3732', 'revid': '264323', 'url': 'https://en.wikipedia.org/wiki?curid=3732', 'title': 'Bangra', 'text': ''}\n"
     ]
    }
   ],
   "source": [
    "redirect_pages = []\n",
    "for kdata in ED_wiki_35:\n",
    "    kdata.keys()\n",
    "    if kdata['text'] == '':\n",
    "        print(kdata)\n",
    "        redirect_pages.append(kdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ed8764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8be09dbb",
   "metadata": {},
   "source": [
    "## Answer the Question: How Many Answers are Wikipages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5d9a4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_text_pages(subseg_path, verbose=False):\n",
    "    no_text_pages = []\n",
    "    for kdata in gu.loadjsonl(subseg_path):\n",
    "        if kdata['clean_text'] == '':\n",
    "            no_text_pages.append(kdata)\n",
    "    return no_text_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cf845d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/ddr8143/wikipedia/tagme_dumps_qampari_wikipedia/'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_args.gt_wiki_dir"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edc2abd9",
   "metadata": {},
   "source": [
    "# Get all of the no text pages\n",
    "all_no_text_pages = wu.process_all_wikipath_subsegs(\n",
    "    input_wikipath=path_args.gt_wiki_dir,\n",
    "    fxn=get_no_text_pages,\n",
    "    verbose=True,\n",
    ")\n",
    "all_no_text_pages_real = []\n",
    "for antp in all_no_text_pages:\n",
    "    all_no_text_pages_real.extend(antp)\n",
    "json.dump(all_no_text_pages_real, open(path_args.no_text_pages, 'w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7aed40b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9574158"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_no_text_pages_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f25b0ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_text_page_titles = set()\n",
    "for p in all_no_text_pages_real:\n",
    "    no_text_page_titles.add(gu.normalize(p['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81154297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2c67c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmp_dev = qu.load_dev_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "e9e6dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers_from_dataset(dataset, answer_fxn):\n",
    "    all_ans = set()\n",
    "    for d in dataset:\n",
    "        for a_dict in d['answer_list']:\n",
    "            a = answer_fxn(a_dict)\n",
    "            if a is None:\n",
    "                continue\n",
    "            all_ans.add(a)\n",
    "    return all_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8bff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "45b61a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normed_answers_to_answerinfo(dataset, answer_fxn, norm_fxn):\n",
    "    answer_dict = {}\n",
    "    for d in dataset:\n",
    "        for a_dict in d['answer_list']:\n",
    "            a = answer_fxn(a_dict)\n",
    "            if a is None or a.strip() == '':\n",
    "                continue\n",
    "            #print(a)\n",
    "            #print(norm_fxn(a))\n",
    "            answer_dict[norm_fxn(a)] = {\n",
    "                \"question_text\": d['question_text'],\n",
    "                **a_dict,\n",
    "            }\n",
    "    return answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "3da67e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_composition(dataset, no_text_titles, text_titles, answer_fxn, norm_fxn):\n",
    "    all_ans = answers_from_dataset(dataset, answer_fxn)\n",
    "    norm_all_ans = set([norm_fxn(a) for a in all_ans if norm_fxn(a) != ''])\n",
    "    in_text = norm_all_ans & text_titles\n",
    "    in_no_text = norm_all_ans & no_text_titles\n",
    "    in_neither = norm_all_ans - in_text - in_no_text\n",
    "    num_ans = len(all_ans)\n",
    "    print(f\"all_ans: {num_ans}| in text: {len(in_text)} | in notext: {len(in_no_text)} | in neither: {len(in_neither)} ({len(in_neither)*100.0 /num_ans:0.2f}%)\")\n",
    "    return in_neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "3fb2f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dev Answer_URLs Missing In Page Titles (default normalize) ===\n",
      "\n",
      "all_ans: 10833| in text: 10808 | in notext: 1144 | in neither: 12\n",
      "\n",
      "2001:_a_space_odyssey_(film)             https://en.wikipedia.org/wiki/2001:_A_Space_Odyssey_(film)\n",
      "armageddon_time                          https://en.wikipedia.org/wiki/Armageddon_Time\n",
      "hexen:_beyond_heretic                    https://en.wikipedia.org/wiki/Hexen:_Beyond_Heretic\n",
      "sydney_trains_a_&_b_sets                 https://en.wikipedia.org/wiki/Sydney_Trains_A_&_B_sets\n",
      "lincoln_zephyr_(china)                   https://en.wikipedia.org/wiki/Lincoln_Zephyr_(China)\n",
      "enemy_territory:_quake_wars              https://en.wikipedia.org/wiki/Enemy_Territory:_Quake_Wars\n",
      "bob_biswas                               https://en.wikipedia.org/wiki/Bob_Biswas\n",
      "chumo_the_holy_of_goguryeo               https://en.wikipedia.org/wiki/Chumo_the_Holy_of_Goguryeo\n",
      "star_trek:_discovery                     https://en.wikipedia.org/wiki/Star_Trek:_Discovery\n",
      "henry_&_june                             https://en.wikipedia.org/wiki/Henry_&_June\n",
      "21_&_over_(film)                         https://en.wikipedia.org/wiki/21_&_Over_(film)\n",
      "mishima:_a_life_in_four_chapters         https://en.wikipedia.org/wiki/Mishima:_A_Life_in_Four_Chapters\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Dev Answer_URLs Missing In Page Titles (default normalize) ===\\n\")\n",
    "in_neither_urls_default = get_answer_composition(qmp_dev, no_text_page_titles, set(all_titles), qu.extract_answer_url, gu.normalize)\n",
    "print()\n",
    "answer_info_urls_default = normed_answers_to_answerinfo(qmp_dev, qu.extract_answer_url, gu.normalize)\n",
    "for a in in_neither_urls_default:\n",
    "    print(f\"{a:40}\", answer_info_urls_default[a]['answer_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "fa218107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dev Answer_URLs Missing In Page Titles (aggressive normalize) ===\n",
      "\n",
      "all_ans: 10833| in text: 10811 | in notext: 1146 | in neither: 7\n",
      "\n",
      "armageddon_time                          https://en.wikipedia.org/wiki/Armageddon_Time\n",
      "lincoln_zephyr_(china)                   https://en.wikipedia.org/wiki/Lincoln_Zephyr_(China)\n",
      "mishima_a_life_in_four_chapters          https://en.wikipedia.org/wiki/Mishima:_A_Life_in_Four_Chapters\n",
      "hexen_beyond_heretic                     https://en.wikipedia.org/wiki/Hexen:_Beyond_Heretic\n",
      "bob_biswas                               https://en.wikipedia.org/wiki/Bob_Biswas\n",
      "chumo_the_holy_of_goguryeo               https://en.wikipedia.org/wiki/Chumo_the_Holy_of_Goguryeo\n",
      "2001_a_space_odyssey_(film)              https://en.wikipedia.org/wiki/2001:_A_Space_Odyssey_(film)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Dev Answer_URLs Missing In Page Titles (aggressive normalize) ===\\n\")\n",
    "in_neither_urls_better = get_answer_composition(qmp_dev, no_text_page_titles, set(all_titles), qu.extract_answer_url, qu.ans_normalize_and_split)\n",
    "print()\n",
    "answer_info_urls_better = normed_answers_to_answerinfo(qmp_dev, qu.extract_answer_url, qu.ans_normalize_and_split)\n",
    "for a in in_neither_urls_better:\n",
    "    print(f\"{a:40}\", answer_info_urls_better[a]['answer_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78b487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "56fbd15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dev Answer Texts Missing In Page Titles (default normalize) ===\n",
      "\n",
      "all_ans: 12462| in text: 10379 | in notext: 2682 | in neither: 899 (7.21%)\n",
      "\n",
      "[[chilis]]                                                                                             |[[Chilis]]|\n",
      "_viktor_gyökeres                                                                                      | Viktor Gyökeres|\n",
      "pakistan_aeronautical_complex_(pac)                                                                    |Pakistan Aeronautical Complex (PAC)|\n",
      "chesapeake_&_delaware_canal_bridge                                                                     |Chesapeake & Delaware Canal Bridge|\n",
      "conning_towers_nautilus_park                                                                           |Conning Towers Nautilus Park|\n",
      "[[soviet_aircraft_carrier_admiral_gorshkov|admiral_flota_sovetskogo_soyuza_gorshkov]]                  |[[Soviet aircraft carrier Admiral Gorshkov|Admiral Flota Sovetskogo Soyuza Gorshkov]]|\n",
      "webcrawler*                                                                                            |WebCrawler*|\n",
      "peros_banhos_atoll,_northern_chagos_archipelago                                                        |Peros Banhos atoll, northern Chagos Archipelago|\n",
      "andrey_pervozvanny                                                                                     |Andrey Pervozvanny|\n",
      "[[ongs_hat]]                                                                                           |[[Ongs Hat]]|\n",
      "_mohamed_kourouma                                                                                      | Mohamed Kourouma|\n",
      "ntt_tower                                                                                              |NTT Tower|\n",
      "käravete_manor                                                                                        |Käravete Manor|\n",
      "usrp_b200__                                                                                            |USRP B200  |\n",
      "[[soviet_aircraft_carrier_novorossiysk|novorossiysk]]                                                  |[[Soviet aircraft carrier Novorossiysk|Novorossiysk]]|\n",
      "governor_harry_w._nice_memorial/senator_thomas_\"mac\"_middleton_bridge                                  |Governor Harry W. Nice Memorial/Senator Thomas \"Mac\" Middleton Bridge|\n",
      "[[japanese_aircraft_carrier_kaga|kaga]]                                                                |[[Japanese aircraft carrier Kaga|Kaga]]|\n",
      "hermann_bridge_(replaced)                                                                              |Hermann Bridge (replaced)|\n",
      "junípero_serra__                                                                                      |Junípero Serra  |\n",
      "röa_manor                                                                                             |Röa Manor|\n",
      "pont-de-coubon,_com._coubon                                                                            |Pont-de-Coubon, com. Coubon|\n",
      "pont-destrouilhas,_le,_communes_of_aiguilhe_and_espaly-saint-marcel                                    |Pont-dEstrouilhas, Le, communes of Aiguilhe and Espaly-Saint-Marcel|\n",
      "gt/gt_c                                                                                                |GT/GT C|\n",
      "gaoligongshan_tunnel_高黎贡山隧道                                                                            |Gaoligongshan Tunnel 高黎贡山隧道|\n",
      "_atiba_harris                                                                                          | Atiba Harris|\n",
      "gogukcheon                                                                                             |Gogukcheon|\n",
      "barrett_m82a1/m107                                                                                     |Barrett M82A1/M107|\n",
      "q:_the_winged_serpent                                                                                  |Q: The Winged Serpent|\n",
      "jack_paglen                                                                                            |Jack Paglen|\n",
      "baltic_1                                                                                               |Baltic 1|\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Dev Answer Texts Missing In Page Titles (default normalize) ===\\n\")\n",
    "in_neither_text_default = get_answer_composition(qmp_dev, no_text_page_titles, set(all_titles), qu.extract_answer_text, gu.normalize)\n",
    "print()\n",
    "answer_info_text_default = normed_answers_to_answerinfo(qmp_dev, qu.extract_answer_text, gu.normalize)\n",
    "for a in list(in_neither_text_default)[:30]:\n",
    "    print(f\"{a:100}   |{answer_info_text_default[a]['answer_text']}|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "170608fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dev Answer Texts Missing In Page Titles (aggressive normalize) ===\n",
      "\n",
      "all_ans: 12462| in text: 10573 | in notext: 2759 | in neither: 651 (5.22%)\n",
      "\n",
      "poems_and_stories                                                                  Poems and Stories\n",
      "russian_ship_of_the_line_imperator_nikolai_i                                       Russian ship of the line Imperator Nikolai I\n",
      "o_ōnomatsu                                                                         o Ōnomatsu\n",
      "hermann_waldaestel                                                                 Hermann Waldaestel\n",
      "semyon_budyonnyy                                                                   Semyon Budyonnyy\n",
      "jen_kamerman                                                                       Jen Kamerman\n",
      "micheon                                                                            Micheon\n",
      "johnny_gravel                                                                      Johnny Gravel\n",
      "ludlow_massacre_strike                                                             Ludlow Massacre Strike\n",
      "perth-class                                                                        Perth-class\n",
      "khety_i_(acthoes_i)                                                                Khety I (Acthoes I)\n",
      "mark_twain_memorial_bridge_(demolished)                                            Mark Twain Memorial Bridge (demolished)\n",
      "tamanishiki_sanemon                                                                [[Tamanishiki Sanemon]]\n",
      "isaac_asimov_presents_the_great_sf_stories_11                                      Isaac Asimov Presents The Great SF Stories 11\n",
      "eastern_shore_centre_(november_17,_2004–present)                                   Eastern Shore Centre (November 17, 2004–present)\n",
      "väätsa_manor                                                                     Väätsa Manor\n",
      "usrp_n200                                                                          USRP N200  \n",
      "badmans_gold                                                                       [[Badmans Gold]]\n",
      "fowler–noll–vo_hash_function_(fnv_hash)                                            Fowler–Noll–Vo hash function (FNV Hash)\n",
      "jeffrey_lee_gibson                                                                 Jeffrey Lee Gibson\n",
      "kurisoo_manor                                                                      Kurisoo Manor\n",
      "dalswinton,_pennyland_moor                                                         Dalswinton, Pennyland Moor\n",
      "mont_dambin_base_tunnel                                                            [[Mont dAmbin Base Tunnel]] https://www.telt-sas.com/en/the-first-9-km-of-the-base-tunnel-completed/  \n",
      "hms_eminent                                                                        HMS Eminent\n",
      "pyramids_of_mars_i                                                                 Pyramids of Mars I\n",
      "vim_robbins,_a.,_hannah,_e.,_&amp;_lamb,_l._(2008)._learning_the_vi_and_vim_editors._\"_oreilly_media,_inc.\"._robbins,_a._(2011)._vi_and_vim_editors_pocket_reference._\"_oreilly_media,_inc.\"._schulz,_k._(2007)._hacking_vim_a_cookbook_to_get_the_most_out_of_the_latest_vim_editor._packt_publishing_ltd._neil,_d._(2015)._practical_vim_edit_text_at_the_speed_of_thought._pragmatic_bookshelf.   vim Robbins, A., Hannah, E., & Lamb, L. (2008). Learning the vi and Vim Editors. \" OReilly Media, Inc.\".  Robbins, A. (2011). Vi and Vim Editors Pocket Reference. \" OReilly Media, Inc.\".  Schulz, K. (2007). Hacking Vim: a cookbook to get the most out of the latest Vim editor. Packt Publishing Ltd.  Neil, D. (2015). Practical Vim: Edit Text at the Speed of Thought. Pragmatic Bookshelf. \n",
      "live_united_bowl                                                                   Live United Bowl\n",
      "warsaw_bridge_(bypassed)                                                           Warsaw Bridge (bypassed)\n",
      "joseph_brutkowski                                                                  Joseph Brutkowski\n",
      "grand_mosque_of_paris_or_great_mosque_of_paris                                     Grand Mosque of Paris or Great Mosque of Paris \n",
      "heart_mountain,_wyoming,_us                                                        Heart Mountain, Wyoming, US\n",
      "emporium_borough†                                                                  Emporium borough†\n",
      "domhnall_spainneach_mac_murrough_caomhánach                                       Domhnall Spainneach Mac Murrough Caomhánach\n",
      "blackwater_creek_fire                                                              Blackwater Creek Fire\n",
      "mosin–nagant_(m1907_carbine)                                                       Mosin–Nagant (M1907 Carbine)\n",
      "st._saviours_gaa                                                                   St. Saviours GAA\n",
      "flying_broom_international_womens_film_festival                                    [[Flying Broom International Womens Film Festival]]\n",
      "museo_dellopera_del_duomo_(florence)                                               [[Museo dellOpera del Duomo (Florence)|Museo dellOpera del Duomo]]\n",
      "isaac_asimov_presents_the_great_sf_stories_10                                      Isaac Asimov Presents The Great SF Stories 10\n",
      "bryan_alvarez_and_dave_meltzer                                                     Bryan Alvarez and Dave Meltzer\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Dev Answer Texts Missing In Page Titles (aggressive normalize) ===\\n\")\n",
    "in_neither_text_better = get_answer_composition(qmp_dev, no_text_page_titles, set(all_titles), qu.extract_answer_text, ans_normalize_and_split)\n",
    "print()\n",
    "answer_info_text_better = normed_answers_to_answerinfo(qmp_dev, qu.extract_answer_text, ans_normalize_and_split)\n",
    "for a in list(in_neither_text_better)[110:150]:\n",
    "    print(f\"{a:80}   {answer_info_text_better[a]['answer_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590941c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to directly match the links\n",
    "# --> If we can do this it dramatically cuts down on the number of wikipedia api calls we'd use even\n",
    "#   if we don't directly match ELQ results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4499ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to directly match the ELQ results\n",
    "# --> if we can do this then we can run ELQ on wikipedia as a whole instead of using the wikipedia api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff17ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0030cfc",
   "metadata": {},
   "source": [
    "## Previously Ran\n",
    "But haven't retested after the refactor."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c670dfb",
   "metadata": {},
   "source": [
    "# Postprocess all of the wikipedia raw tag dumps\n",
    "all_paths = wu.wikipedia_title_to_links_tagmes_strs(\n",
    "    path_args,\n",
    "    output_name='title2linktagmestrs',\n",
    "    verbose=True,\n",
    "    force=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf410158",
   "metadata": {},
   "source": [
    "# Postprocess the gpt answers\n",
    "ru.convert_gpt_raw_to_structured(\n",
    "    path_args.gpt_ans_raw_path,\n",
    "    path_args.gpt_ans_path,\n",
    "    force=False,\n",
    ")\n",
    "gpt_ans = json.load(open(path_args.gpt_ans_path))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6debde3",
   "metadata": {},
   "source": [
    "# Add all the different ent_strings to the list for\n",
    "#   updating the cache.\n",
    "aggregate_strs_to_add_to_cache(\n",
    "    path_args,\n",
    "    add_elq=True,\n",
    "    add_gpt=True,\n",
    "    add_wikitags=True,\n",
    "    use_tqdm=True,\n",
    "    curr_cache=curr_cache,\n",
    ")\n",
    ">> After Adding ELQ: 1224\n",
    ">> After Adding GPT3: 4336\n",
    ">> After Adding Wikipedia Tags and Links: 9072313\n",
    ">> Dumped to: /scratch/ddr8143/wikipedia/tagme_dumps_qampari_wikipedia/postprocessed/strs_to_add_to_cache_v0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd22a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
